{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ccc570",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# --- AZURE CONFIGURATION ---\n",
    "STORAGE_ACCOUNT = \"beehavenstorage\"\n",
    "CONTAINER_SILVER = \"silver\"\n",
    "CONTAINER_GOLD = \"gold\"\n",
    "\n",
    "# URI Construction\n",
    "SILVER_URI = f\"abfss://{CONTAINER_SILVER}@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "GOLD_URI = f\"abfss://{CONTAINER_GOLD}@{STORAGE_ACCOUNT}.dfs.core.windows.net\"\n",
    "\n",
    "def load_silver_data(entity_name):\n",
    "    \"\"\"\n",
    "    Reads the latest Parquet file from the Silver layer for a given entity.\n",
    "    \"\"\"\n",
    "    # In a real scenario, we might read a partitioned folder or specific run ID\n",
    "    path = f\"{SILVER_URI}/{entity_name}/\"\n",
    "    print(f\"Loading {entity_name} from {path}...\")\n",
    "    try:\n",
    "        # This requires the Identity to have RBAC permissions on the Lake\n",
    "        return pd.read_parquet(path)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not read {entity_name}. Error: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def process_daily_metrics(df_flow, df_weight, df_temp, df_humidity, df_weather):\n",
    "    \"\"\"\n",
    "    Aggregates all disparate time-series into a unified DAILY Hive Health Table.\n",
    "    \"\"\"\n",
    "    print(\"Aggregating data to Daily frequency...\")\n",
    "\n",
    "    # 1. Standardize Timestamps\n",
    "    # Ensure all inputs have a datetime index for resampling\n",
    "    for df in [df_flow, df_weight, df_temp, df_humidity]:\n",
    "        if not df.empty and 'timestamp' in df.columns:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "            df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # 2. Resample & Aggregate (The Core Logic)\n",
    "    \n",
    "    # Flow: Sum of flow indicates total activity\n",
    "    daily_flow = df_flow.resample('D')['flow'].sum().rename(\"total_flow_count\")\n",
    "    \n",
    "    # Weight: We care about the CHANGE in weight (Honey production), not just absolute weight\n",
    "    # We take the max of the day minus the min of the day\n",
    "    daily_weight = df_weight.resample('D')['weight'].apply(lambda x: x.max() - x.min()).rename(\"daily_weight_change_kg\")\n",
    "    \n",
    "    # Temperature: Average is fine, but Max/Min is better for biological stress\n",
    "    daily_temp = df_temp.resample('D')['temperature'].agg(['mean', 'max', 'min'])\n",
    "    daily_temp.columns = ['avg_temp_c', 'max_temp_c', 'min_temp_c']\n",
    "\n",
    "    # Humidity: Average\n",
    "    daily_humidity = df_humidity.resample('D')['humidity'].mean().rename(\"avg_humidity_percent\")\n",
    "\n",
    "    # 3. Join with External Weather Data\n",
    "    # Assuming weather is already daily or needs resampling\n",
    "    if not df_weather.empty:\n",
    "        df_weather['timestamp'] = pd.to_datetime(df_weather['timestamp'])\n",
    "        df_weather.set_index('timestamp', inplace=True)\n",
    "        daily_weather = df_weather.resample('D').mean() # Simplified for example\n",
    "    else:\n",
    "        daily_weather = pd.DataFrame()\n",
    "\n",
    "    # 4. Merge All into One \"Golden Table\"\n",
    "    gold_df = pd.concat([daily_flow, daily_weight, daily_temp, daily_humidity], axis=1)\n",
    "    \n",
    "    # Join external weather (Left join because we prioritize our sensor data)\n",
    "    if not daily_weather.empty:\n",
    "        gold_df = gold_df.join(daily_weather, rsuffix='_external')\n",
    "\n",
    "    # 5. Feature Engineering (Metrics for Data Science)\n",
    "    # Calculate \"Efficiency\": Flow per degree of temperature\n",
    "    gold_df['activity_per_degree'] = gold_df['total_flow_count'] / gold_df['avg_temp_c']\n",
    "    \n",
    "    return gold_df.reset_index()\n",
    "\n",
    "def main():\n",
    "    # 1. Load Data\n",
    "    df_flow = load_silver_data(\"flow\")\n",
    "    df_weight = load_silver_data(\"weight\")\n",
    "    df_temp = load_silver_data(\"temperature\")\n",
    "    df_humidity = load_silver_data(\"humidity\")\n",
    "    df_weather = load_silver_data(\"weather\")\n",
    "\n",
    "    # 2. Transform\n",
    "    gold_df = process_daily_metrics(df_flow, df_weight, df_temp, df_humidity, df_weather)\n",
    "\n",
    "    # 3. Write to Gold\n",
    "    current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    output_path = f\"{GOLD_URI}/hive_health_daily/hive_health_{current_date}.parquet\"\n",
    "    \n",
    "    print(f\"Writing {len(gold_df)} rows to Gold Layer: {output_path}\")\n",
    "    gold_df.to_parquet(output_path, index=False)\n",
    "    \n",
    "    print(\"Gold transformation complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
